{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a89f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tldextract\n",
    "from scipy.sparse import coo_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03911c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('url _classification.csv', header = None)\n",
    "df.columns = [\"index\" , \"url\" , \"label\"]\n",
    "# df[\"url\"]= df[\"URL\"].astype(str)\n",
    "# data = pd.DataFrame(df)\n",
    "# data.dtypes\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b74b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_protocol(url:str):\n",
    "    delim = \"://\"\n",
    "    if delim in url:\n",
    "        n = url.index(delim)\n",
    "        return [url[:n], url[n + len(delim):]]\n",
    "    else:\n",
    "        return ['', url]\n",
    "    return ['', url]\n",
    "\n",
    "split_protocol_data = df['url'].apply(lambda x: split_protocol(x))\n",
    "df = pd.concat([df, pd.DataFrame(split_protocol_data.tolist(), columns=['protocol', 'url_2'])], axis=1)\n",
    "# split_protocol_data = dt['url'].apply(lambda x: split_protocol(x))\n",
    "# dt = pd.concat([dt, pd.DataFrame(split_protocol_data.tolist(), columns=['protocol', 'url_2'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f63f1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_number(input: str): \n",
    "    n = len(input)\n",
    "    output = \"\"\n",
    "    prev_is_number = False\n",
    "    nums = []\n",
    "    for i in range(10):\n",
    "        nums.append(str(i))\n",
    "    for i in range(n):\n",
    "        if input[i] in nums:\n",
    "            if prev_is_number:\n",
    "                continue\n",
    "            else:\n",
    "                output = output + '1'\n",
    "                prev_is_number = True\n",
    "        else:\n",
    "            output = output + input[i]\n",
    "            prev_is_number = False\n",
    "    return output\n",
    "\n",
    "no__num_data = list(map(lambda url: generalize_number(url),  df['url_2']))\n",
    "df = pd.concat([df, pd.DataFrame(no__num_data, columns=['url_no_num'])], axis=1)\n",
    "\n",
    "\n",
    "# no__num_data = list(map(lambda url: generalize_number(url),  dt['url_2']))\n",
    "# dt = pd.concat([dt, pd.DataFrame(no__num_data, columns=['url_no_num'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e742e006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "      <th>protocol</th>\n",
       "      <th>url_2</th>\n",
       "      <th>url_no_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>http://www2.117.ne.jp/~mb1996ax/enadc.html</td>\n",
       "      <td>Adult</td>\n",
       "      <td>http</td>\n",
       "      <td>www2.117.ne.jp/~mb1996ax/enadc.html</td>\n",
       "      <td>www1.1.ne.jp/~mb1ax/enadc.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>http://www9.kinghost.com/fetish/hentaibee/</td>\n",
       "      <td>Adult</td>\n",
       "      <td>http</td>\n",
       "      <td>www9.kinghost.com/fetish/hentaibee/</td>\n",
       "      <td>www1.kinghost.com/fetish/hentaibee/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>http://www.geocities.com/kaseychan17/index.html</td>\n",
       "      <td>Adult</td>\n",
       "      <td>http</td>\n",
       "      <td>www.geocities.com/kaseychan17/index.html</td>\n",
       "      <td>www.geocities.com/kaseychan1/index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>http://e.webring.com/hub?sid=&amp;amp;ring=hentff9...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>http</td>\n",
       "      <td>e.webring.com/hub?sid=&amp;amp;ring=hentff98&amp;amp;i...</td>\n",
       "      <td>e.webring.com/hub?sid=&amp;amp;ring=hentff1&amp;amp;id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>http://www.geocities.com/eddie_monsoon2002/</td>\n",
       "      <td>Adult</td>\n",
       "      <td>http</td>\n",
       "      <td>www.geocities.com/eddie_monsoon2002/</td>\n",
       "      <td>www.geocities.com/eddie_monsoon1/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562935</th>\n",
       "      <td>1562939</td>\n",
       "      <td>http://ejmas.com/jwma/articles/2000/jwmaart_ro...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>http</td>\n",
       "      <td>ejmas.com/jwma/articles/2000/jwmaart_roberts_0...</td>\n",
       "      <td>ejmas.com/jwma/articles/1/jwmaart_roberts_1.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562936</th>\n",
       "      <td>1562940</td>\n",
       "      <td>http://ejmas.com/jwma/articles/2000/jwmaart_pf...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>http</td>\n",
       "      <td>ejmas.com/jwma/articles/2000/jwmaart_pfrenger_...</td>\n",
       "      <td>ejmas.com/jwma/articles/1/jwmaart_pfrenger_1.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562937</th>\n",
       "      <td>1562941</td>\n",
       "      <td>http://ejmas.com/jwma/articles/2000/jwmaart_ka...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>http</td>\n",
       "      <td>ejmas.com/jwma/articles/2000/jwmaart_kautz_010...</td>\n",
       "      <td>ejmas.com/jwma/articles/1/jwmaart_kautz_1.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562939</th>\n",
       "      <td>1562943</td>\n",
       "      <td>http://ejmas.com/jalt/jaltart_baxter_0102.htm</td>\n",
       "      <td>Sports</td>\n",
       "      <td>http</td>\n",
       "      <td>ejmas.com/jalt/jaltart_baxter_0102.htm</td>\n",
       "      <td>ejmas.com/jalt/jaltart_baxter_1.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562949</th>\n",
       "      <td>1562953</td>\n",
       "      <td>http://ed-web3.educ.msu.edu/ysi/</td>\n",
       "      <td>Sports</td>\n",
       "      <td>http</td>\n",
       "      <td>ed-web3.educ.msu.edu/ysi/</td>\n",
       "      <td>ed-web1.educ.msu.edu/ysi/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276802 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index                                                url   label  \\\n",
       "6              7         http://www2.117.ne.jp/~mb1996ax/enadc.html   Adult   \n",
       "14            15         http://www9.kinghost.com/fetish/hentaibee/   Adult   \n",
       "16            17    http://www.geocities.com/kaseychan17/index.html   Adult   \n",
       "18            19  http://e.webring.com/hub?sid=&amp;ring=hentff9...   Adult   \n",
       "23            24        http://www.geocities.com/eddie_monsoon2002/   Adult   \n",
       "...          ...                                                ...     ...   \n",
       "1562935  1562939  http://ejmas.com/jwma/articles/2000/jwmaart_ro...  Sports   \n",
       "1562936  1562940  http://ejmas.com/jwma/articles/2000/jwmaart_pf...  Sports   \n",
       "1562937  1562941  http://ejmas.com/jwma/articles/2000/jwmaart_ka...  Sports   \n",
       "1562939  1562943      http://ejmas.com/jalt/jaltart_baxter_0102.htm  Sports   \n",
       "1562949  1562953                   http://ed-web3.educ.msu.edu/ysi/  Sports   \n",
       "\n",
       "        protocol                                              url_2  \\\n",
       "6           http                www2.117.ne.jp/~mb1996ax/enadc.html   \n",
       "14          http                www9.kinghost.com/fetish/hentaibee/   \n",
       "16          http           www.geocities.com/kaseychan17/index.html   \n",
       "18          http  e.webring.com/hub?sid=&amp;ring=hentff98&amp;i...   \n",
       "23          http               www.geocities.com/eddie_monsoon2002/   \n",
       "...          ...                                                ...   \n",
       "1562935     http  ejmas.com/jwma/articles/2000/jwmaart_roberts_0...   \n",
       "1562936     http  ejmas.com/jwma/articles/2000/jwmaart_pfrenger_...   \n",
       "1562937     http  ejmas.com/jwma/articles/2000/jwmaart_kautz_010...   \n",
       "1562939     http             ejmas.com/jalt/jaltart_baxter_0102.htm   \n",
       "1562949     http                          ed-web3.educ.msu.edu/ysi/   \n",
       "\n",
       "                                                url_no_num  \n",
       "6                           www1.1.ne.jp/~mb1ax/enadc.html  \n",
       "14                     www1.kinghost.com/fetish/hentaibee/  \n",
       "16                 www.geocities.com/kaseychan1/index.html  \n",
       "18       e.webring.com/hub?sid=&amp;ring=hentff1&amp;id...  \n",
       "23                       www.geocities.com/eddie_monsoon1/  \n",
       "...                                                    ...  \n",
       "1562935    ejmas.com/jwma/articles/1/jwmaart_roberts_1.htm  \n",
       "1562936   ejmas.com/jwma/articles/1/jwmaart_pfrenger_1.htm  \n",
       "1562937      ejmas.com/jwma/articles/1/jwmaart_kautz_1.htm  \n",
       "1562939                ejmas.com/jalt/jaltart_baxter_1.htm  \n",
       "1562949                          ed-web1.educ.msu.edu/ysi/  \n",
       "\n",
       "[276802 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['url_2'] != df['url_no_num']]\n",
    "# dt[dt['url_2'] != dt['url_no_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "935b7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_prefix(url:str):\n",
    "    pattern = re.compile('^(?P<prefix>w*[\\d]*)\\.(?P<fulldomain>.*)')\n",
    "    match = re.match(pattern, url)\n",
    "    if match is None:\n",
    "        return ['', url]\n",
    "    else:\n",
    "        split = match.groupdict()\n",
    "        return [split['prefix'], split['fulldomain']]\n",
    "\n",
    "split_prefix_data = list(map(lambda url: split_prefix(url),  df['url_no_num']))\n",
    "df = pd.concat([df, pd.DataFrame(split_prefix_data, columns=['prefix', 'fulldomain'])], axis=1)\n",
    "\n",
    "\n",
    "# split_prefix_data = list(map(lambda url: split_prefix(url),  dt['url_no_num']))\n",
    "# dt = pd.concat([dt, pd.DataFrame(split_prefix_data, columns=['prefix', 'fulldomain'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adb3473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['url_2'])\n",
    "# dt = dt.drop(columns=['url_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9d0411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_url_uri(url:str):\n",
    "    delim = \"/\"\n",
    "    if delim in url:\n",
    "        n = url.index(delim)\n",
    "        return [url[:n], url[n + len(delim):]]\n",
    "    else:\n",
    "        return [url, '']\n",
    "\n",
    "split_url_uri_data = df['fulldomain'].apply(lambda x: split_url_uri(x))\n",
    "df = pd.concat([df, pd.DataFrame(split_url_uri_data.tolist(), columns=['urlonly', 'directory'])], axis=1)\n",
    "\n",
    "# split_url_uri_data = dt['fulldomain'].apply(lambda x: split_url_uri(x))\n",
    "# dt = pd.concat([dt, pd.DataFrame(split_url_uri_data.tolist(), columns=['urlonly', 'uri'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "067a0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_url(url):\n",
    "    # extract subdomain, domain, and domain suffix from url\n",
    "    # if item == '', fill with '<empty>'\n",
    "    subdomain, domain, domain_suffix = ('' if extracted == '' else extracted for extracted in tldextract.extract(url))\n",
    "    \n",
    "    return [subdomain, domain, domain_suffix]\n",
    "\n",
    "# parsed url\n",
    "extract_url_data = [split_url(url) for url in df['fulldomain']]\n",
    "extract_url_data = pd.DataFrame(extract_url_data, columns=['subdomain', 'domain', 'domain_suffix'])\n",
    "\n",
    "\n",
    "# extract_url_data = [split_url(url) for url in dt['fulldomain']]\n",
    "# extract_url_data = pd.DataFrame(extract_url_data, columns=['subdomain', 'domain', 'domain_suffix'])\n",
    "\n",
    "# concat extracted feature with main data\n",
    "data = df.reset_index(drop=True)\n",
    "df = pd.concat([df, extract_url_data], axis=1)\n",
    "\n",
    "# data = dt.reset_index(drop=True)\n",
    "# dt = pd.concat([dt, extract_url_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35237f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['domain_suffix'] = df['domain_suffix'].apply(lambda x: x.replace('.', ' '))\n",
    "df['domain_suffix'] = df['domain_suffix'].apply(lambda x: x.strip())\n",
    "\n",
    "df['directory'] = df['directory'].apply(lambda x: x.replace('.', ' '))\n",
    "df['directory'] = df['directory'].apply(lambda x: x.replace('/', ' '))\n",
    "df['directory'] = df['directory'].apply(lambda x: x.replace('?', ' '))\n",
    "df['directory'] = df['directory'].apply(lambda x: x.replace('=', ' '))\n",
    "df['directory'] = df['directory'].apply(lambda x: x.replace('-', ' '))\n",
    "df['directory'] = df['directory'].apply(lambda x: x.strip())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dt['domain_suffix'] = dt['domain_suffix'].apply(lambda x: x.replace('.', ' '))\n",
    "# dt['domain_suffix'] = dt['domain_suffix'].apply(lambda x: x.strip())\n",
    "\n",
    "# dt['uri'] = dt['uri'].apply(lambda x: x.replace('.', ' '))\n",
    "# dt['uri'] = dt['uri'].apply(lambda x: x.replace('/', ' '))\n",
    "# dt['uri'] = dt['uri'].apply(lambda x: x.replace('?', ' '))\n",
    "# dt['uri'] = dt['uri'].apply(lambda x: x.replace('=', ' '))\n",
    "# dt['uri'] = dt['uri'].apply(lambda x: x.replace('-', ' '))\n",
    "# dt['uri'] = dt['uri'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "671ad89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43d2d67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "      <th>protocol</th>\n",
       "      <th>url_no_num</th>\n",
       "      <th>prefix</th>\n",
       "      <th>fulldomain</th>\n",
       "      <th>urlonly</th>\n",
       "      <th>directory</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>domain</th>\n",
       "      <th>domain_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1562965</th>\n",
       "      <td>1562969</td>\n",
       "      <td>http://www.aodonline.org/chsl/chsl.htm</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>www.aodonline.org/chsl/chsl.htm</td>\n",
       "      <td>www</td>\n",
       "      <td>aodonline.org/chsl/chsl.htm</td>\n",
       "      <td>aodonline.org</td>\n",
       "      <td>chsl chsl htm</td>\n",
       "      <td></td>\n",
       "      <td>aodonline</td>\n",
       "      <td>org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562966</th>\n",
       "      <td>1562970</td>\n",
       "      <td>http://aenwebsites.com/tsl/</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>aenwebsites.com/tsl/</td>\n",
       "      <td></td>\n",
       "      <td>aenwebsites.com/tsl/</td>\n",
       "      <td>aenwebsites.com</td>\n",
       "      <td>tsl</td>\n",
       "      <td></td>\n",
       "      <td>aenwebsites</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562967</th>\n",
       "      <td>1562971</td>\n",
       "      <td>http://www.fciac.net/</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>www.fciac.net/</td>\n",
       "      <td>www</td>\n",
       "      <td>fciac.net/</td>\n",
       "      <td>fciac.net</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>fciac</td>\n",
       "      <td>net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562968</th>\n",
       "      <td>1562972</td>\n",
       "      <td>http://www.infosports.com/</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>www.infosports.com/</td>\n",
       "      <td>www</td>\n",
       "      <td>infosports.com/</td>\n",
       "      <td>infosports.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>infosports</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562969</th>\n",
       "      <td>1562973</td>\n",
       "      <td>http://www.hssp.cc/</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>www.hssp.cc/</td>\n",
       "      <td>www</td>\n",
       "      <td>hssp.cc/</td>\n",
       "      <td>hssp.cc</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hssp</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562970</th>\n",
       "      <td>1562974</td>\n",
       "      <td>http://www.maxpreps.com/</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>www.maxpreps.com/</td>\n",
       "      <td>www</td>\n",
       "      <td>maxpreps.com/</td>\n",
       "      <td>maxpreps.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>maxpreps</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562971</th>\n",
       "      <td>1562975</td>\n",
       "      <td>http://www.myscore.com/</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>www.myscore.com/</td>\n",
       "      <td>www</td>\n",
       "      <td>myscore.com/</td>\n",
       "      <td>myscore.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>myscore</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562972</th>\n",
       "      <td>1562976</td>\n",
       "      <td>http://sportsillustrated.cnn.com/highschool</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>sportsillustrated.cnn.com/highschool</td>\n",
       "      <td></td>\n",
       "      <td>sportsillustrated.cnn.com/highschool</td>\n",
       "      <td>sportsillustrated.cnn.com</td>\n",
       "      <td>highschool</td>\n",
       "      <td>sportsillustrated</td>\n",
       "      <td>cnn</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562973</th>\n",
       "      <td>1562977</td>\n",
       "      <td>http://rss.cnn.com/rss/si_highschool?format=xml</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>rss.cnn.com/rss/si_highschool?format=xml</td>\n",
       "      <td></td>\n",
       "      <td>rss.cnn.com/rss/si_highschool?format=xml</td>\n",
       "      <td>rss.cnn.com</td>\n",
       "      <td>rss si_highschool format xml</td>\n",
       "      <td>rss</td>\n",
       "      <td>cnn</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562974</th>\n",
       "      <td>1562978</td>\n",
       "      <td>http://www.usatoday.com/sports/preps/</td>\n",
       "      <td>13</td>\n",
       "      <td>http</td>\n",
       "      <td>www.usatoday.com/sports/preps/</td>\n",
       "      <td>www</td>\n",
       "      <td>usatoday.com/sports/preps/</td>\n",
       "      <td>usatoday.com</td>\n",
       "      <td>sports preps</td>\n",
       "      <td></td>\n",
       "      <td>usatoday</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index                                              url  label  \\\n",
       "1562965  1562969           http://www.aodonline.org/chsl/chsl.htm     13   \n",
       "1562966  1562970                      http://aenwebsites.com/tsl/     13   \n",
       "1562967  1562971                            http://www.fciac.net/     13   \n",
       "1562968  1562972                       http://www.infosports.com/     13   \n",
       "1562969  1562973                              http://www.hssp.cc/     13   \n",
       "1562970  1562974                         http://www.maxpreps.com/     13   \n",
       "1562971  1562975                          http://www.myscore.com/     13   \n",
       "1562972  1562976      http://sportsillustrated.cnn.com/highschool     13   \n",
       "1562973  1562977  http://rss.cnn.com/rss/si_highschool?format=xml     13   \n",
       "1562974  1562978            http://www.usatoday.com/sports/preps/     13   \n",
       "\n",
       "        protocol                                url_no_num prefix  \\\n",
       "1562965     http           www.aodonline.org/chsl/chsl.htm    www   \n",
       "1562966     http                      aenwebsites.com/tsl/          \n",
       "1562967     http                            www.fciac.net/    www   \n",
       "1562968     http                       www.infosports.com/    www   \n",
       "1562969     http                              www.hssp.cc/    www   \n",
       "1562970     http                         www.maxpreps.com/    www   \n",
       "1562971     http                          www.myscore.com/    www   \n",
       "1562972     http      sportsillustrated.cnn.com/highschool          \n",
       "1562973     http  rss.cnn.com/rss/si_highschool?format=xml          \n",
       "1562974     http            www.usatoday.com/sports/preps/    www   \n",
       "\n",
       "                                       fulldomain                    urlonly  \\\n",
       "1562965               aodonline.org/chsl/chsl.htm              aodonline.org   \n",
       "1562966                      aenwebsites.com/tsl/            aenwebsites.com   \n",
       "1562967                                fciac.net/                  fciac.net   \n",
       "1562968                           infosports.com/             infosports.com   \n",
       "1562969                                  hssp.cc/                    hssp.cc   \n",
       "1562970                             maxpreps.com/               maxpreps.com   \n",
       "1562971                              myscore.com/                myscore.com   \n",
       "1562972      sportsillustrated.cnn.com/highschool  sportsillustrated.cnn.com   \n",
       "1562973  rss.cnn.com/rss/si_highschool?format=xml                rss.cnn.com   \n",
       "1562974                usatoday.com/sports/preps/               usatoday.com   \n",
       "\n",
       "                            directory          subdomain       domain  \\\n",
       "1562965                 chsl chsl htm                       aodonline   \n",
       "1562966                           tsl                     aenwebsites   \n",
       "1562967                                                         fciac   \n",
       "1562968                                                    infosports   \n",
       "1562969                                                          hssp   \n",
       "1562970                                                      maxpreps   \n",
       "1562971                                                       myscore   \n",
       "1562972                    highschool  sportsillustrated          cnn   \n",
       "1562973  rss si_highschool format xml                rss          cnn   \n",
       "1562974                  sports preps                        usatoday   \n",
       "\n",
       "        domain_suffix  \n",
       "1562965           org  \n",
       "1562966           com  \n",
       "1562967           net  \n",
       "1562968           com  \n",
       "1562969            cc  \n",
       "1562970           com  \n",
       "1562971           com  \n",
       "1562972           com  \n",
       "1562973           com  \n",
       "1562974           com  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set(df['label'])\n",
    "label2idx = {k: i for i, k in enumerate(unique_labels)}\n",
    "idx2label = {i: k for k, i in label2idx.items()}\n",
    "\n",
    "# Multiclass classification\n",
    "df['label'] = df['label'].map(label2idx)\n",
    "\n",
    "# Binary Classification\n",
    "# df['label'] = df['label'].apply(lambda x: 0 if x == 'Adult' else 1)\n",
    "\n",
    "\n",
    "# unique_labels = set(dt['label'])\n",
    "# label2idx = {k: i for i, k in enumerate(unique_labels)}\n",
    "# idx2label = {i: k for k, i in label2idx.items()}\n",
    "\n",
    "# # Multiclass classification\n",
    "# dt['label'] = dt['label'].map(label2idx)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a2b3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e72498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(Training_data,\n",
    "                                            test_size=0.2, \n",
    "                                            random_state = 2000,\n",
    "                                            stratify=Training_data['label'])\n",
    "\n",
    "# GET LABELS\n",
    "Y_train=training_data['label'].values\n",
    "Y_test=testing_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0262dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     203072\n",
       "12    195154\n",
       "9     192141\n",
       "11     94369\n",
       "10     88229\n",
       "1      85269\n",
       "13     81062\n",
       "5      76216\n",
       "6      48077\n",
       "4      46598\n",
       "7      45181\n",
       "8      36946\n",
       "3      28260\n",
       "14     22615\n",
       "0       7191\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f624e652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1250380x2963983 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 41393017 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features(field, df, test_data):\n",
    "    # TF-IDF BASED FEATURE REPRESENTATION\n",
    "    tfidf_vectorizer=TfidfVectorizer(use_idf=True, \n",
    "                                    analyzer='char_wb',\n",
    "                                    max_df = 0.95,\n",
    "                                    ngram_range=(3, 6), \n",
    "                                    sublinear_tf=True)\n",
    "    tfidf_vectorizer.fit_transform(training_data[field].values)\n",
    "\n",
    "    train_feature_set=tfidf_vectorizer.transform(training_data[field].values)\n",
    "    test_feature_set=tfidf_vectorizer.transform(testing_data[field].values)\n",
    "    \n",
    "\n",
    "    \n",
    "#     train_feature_set = pad_sequences(train_feature_set, maxlen=10000, padding='post')\n",
    "#     test_feature_set = pad_sequences(test_feature_set, maxlen=10000, padding='post')\n",
    "\n",
    "\n",
    "    return train_feature_set,test_feature_set,tfidf_vectorizer\n",
    "# GET FEATURES\n",
    "X_train1,X_test1,feature_transformer1=extract_features('domain',training_data,testing_data)\n",
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51029b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1250380x693364 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5091754 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features_subdomain(field, train_data, test_data):\n",
    "    # TF-IDF BASED FEATURE REPRESENTATION\n",
    "    tfidf_vectorizer=TfidfVectorizer(use_idf=True, \n",
    "                                    analyzer='char_wb',\n",
    "                                    max_df = 0.95,\n",
    "                                    ngram_range=(3, 6), \n",
    "                                    sublinear_tf=True)\n",
    "    tfidf_vectorizer.fit_transform(training_data[field].values)\n",
    "\n",
    "    train_feature_set=tfidf_vectorizer.transform(training_data[field].values)\n",
    "    test_feature_set=tfidf_vectorizer.transform(testing_data[field].values)\n",
    "    \n",
    "\n",
    "    return train_feature_set,test_feature_set,tfidf_vectorizer\n",
    "\n",
    "X_train2,X_test2,feature_transformer2=extract_features_subdomain('subdomain',training_data,testing_data)\n",
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3e751b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1250380x2098740 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28705319 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features_uri(field, train_data, test_data):\n",
    "    # TF-IDF BASED FEATURE REPRESENTATION\n",
    "    tfidf_vectorizer=TfidfVectorizer(use_idf=True, \n",
    "                                    analyzer='char_wb',\n",
    "                                    max_df = 0.95,\n",
    "                                    ngram_range=(3,6), \n",
    "                                    sublinear_tf=True)\n",
    "    tfidf_vectorizer.fit_transform(training_data[field].values)\n",
    "\n",
    "    train_feature_set=tfidf_vectorizer.transform(training_data[field].values)\n",
    "    test_feature_set=tfidf_vectorizer.transform(testing_data[field].values)\n",
    "    \n",
    "\n",
    "    return train_feature_set,test_feature_set,tfidf_vectorizer\n",
    "\n",
    "X_train3,X_test3,feature_transformer3=extract_features_uri('directory',training_data,testing_data)\n",
    "X_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ac92141",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([X_train1, X_train2, X_train3])\n",
    "X_test = hstack([X_test1, X_test2, X_test3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a840136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<312595x5756087 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17997301 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72f41eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sylvesteranthony/miniforge3/envs/tf/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/sylvesteranthony/miniforge3/envs/tf/lib/python3.10/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:12:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:17:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:23:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:29:33] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:35:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:41:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:47:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:53:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:59:28] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:06:06] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:13:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:20:33] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:27:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:33:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = OneVsRestClassifier(XGBClassifier()).fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b52c08be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.30      0.39      1798\n",
      "           1       0.67      0.34      0.46     21317\n",
      "           2       0.54      0.61      0.57     50768\n",
      "           3       0.85      0.55      0.67      7065\n",
      "           4       0.57      0.45      0.50     11649\n",
      "           5       0.57      0.26      0.36     19054\n",
      "           6       0.70      0.42      0.52     12020\n",
      "           7       0.74      0.56      0.64     11296\n",
      "           8       0.59      0.24      0.34      9236\n",
      "           9       0.34      0.81      0.48     48035\n",
      "          10       0.67      0.44      0.53     22057\n",
      "          11       0.64      0.39      0.48     23592\n",
      "          12       0.60      0.48      0.53     48788\n",
      "          13       0.80      0.59      0.68     20266\n",
      "          14       0.81      0.50      0.62      5654\n",
      "\n",
      "    accuracy                           0.52    312595\n",
      "   macro avg       0.64      0.46      0.52    312595\n",
      "weighted avg       0.59      0.52      0.52    312595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "print(classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58e600e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = OneVsRestClassifier(LinearSVC()).fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1fd2ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.33      0.39      1798\n",
      "           1       0.58      0.53      0.55     21317\n",
      "           2       0.63      0.71      0.66     50768\n",
      "           3       0.82      0.67      0.73      7065\n",
      "           4       0.57      0.52      0.54     11649\n",
      "           5       0.46      0.41      0.43     19054\n",
      "           6       0.66      0.57      0.61     12020\n",
      "           7       0.71      0.63      0.67     11296\n",
      "           8       0.51      0.35      0.42      9236\n",
      "           9       0.54      0.65      0.59     48035\n",
      "          10       0.64      0.59      0.62     22057\n",
      "          11       0.59      0.57      0.58     23592\n",
      "          12       0.64      0.66      0.65     48788\n",
      "          13       0.74      0.71      0.72     20266\n",
      "          14       0.74      0.58      0.65      5654\n",
      "\n",
      "    accuracy                           0.61    312595\n",
      "   macro avg       0.62      0.56      0.59    312595\n",
      "weighted avg       0.61      0.61      0.61    312595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "print(classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84b089c6-c37e-44f2-974a-e6b9a8aa392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = OneVsRestClassifier(MultinomialNB()).fit(X_train, Y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84e4b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03      1798\n",
      "           1       0.76      0.25      0.37     21317\n",
      "           2       0.46      0.72      0.56     50768\n",
      "           3       0.96      0.43      0.60      7065\n",
      "           4       0.73      0.25      0.38     11649\n",
      "           5       0.66      0.15      0.24     19054\n",
      "           6       0.84      0.28      0.41     12020\n",
      "           7       0.77      0.45      0.57     11296\n",
      "           8       0.86      0.12      0.22      9236\n",
      "           9       0.38      0.82      0.52     48035\n",
      "          10       0.62      0.51      0.56     22057\n",
      "          11       0.74      0.33      0.46     23592\n",
      "          12       0.53      0.62      0.57     48788\n",
      "          13       0.83      0.50      0.63     20266\n",
      "          14       0.95      0.34      0.51      5654\n",
      "\n",
      "    accuracy                           0.52    312595\n",
      "   macro avg       0.74      0.39      0.44    312595\n",
      "weighted avg       0.62      0.52      0.50    312595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "print(classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1f961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
